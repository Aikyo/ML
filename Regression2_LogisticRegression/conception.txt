Logistic Regression
    Logistic regression is another technique borrowed by machine learning from the field of statistics.
    It is the go-to method for binary classification problems (problems with two class values).




Logistic Function
    Logistic regression is named for the function used at the core of the method, the logistic function.

    The logistic function, also called the sigmoid function was developed by statisticians to describe
    properties of population growth in ecology, rising quickly and maxing out at the carrying capacity
    of the environment. It’s an S-shaped curve that can take any real-valued number and map it into a
    value between 0 and 1, but never exactly at those limits.

    1 / (1 + e^-value)

    Where e is the base of the natural logarithms (Euler’s number or the EXP() function in your spreadsheet)
     and value is the actual numerical value that you want to transform. Below is a plot of the numbers
     between -5 and 5 transformed into the range 0 and 1 using the logistic function.


Representation Used for Logistic Regression
    Logistic regression uses an equation as the representation, very much like linear regression.

    Input values (x) are combined linearly using weights or coefficient values (referred to as the Greek
    capital letter Beta) to predict an output value (y). A key difference from linear regression is that
    the output value being modeled is a binary values (0 or 1) rather than a numeric value.

    Below is an example logistic regression equation:

    y = e^(b0 + b1*x) / (1 + e^(b0 + b1*x))

    Where y is the predicted output, b0 is the bias or intercept term and b1 is the coefficient for the
    single input value (x). Each column in your input data has an associated b coefficient (a constant
    real value) that must be learned from your training data.

    The actual representation of the model that you would store in memory or in a file are the coefficients
    in the equation (the beta value or b’s).